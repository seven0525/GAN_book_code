{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GANの実装\n",
    "- Google Colabratory上での実装を想定している点にご注意ください "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Googleドライブをマウント（生成画像をドライブに保存するため）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorflow_version 1.x\n",
    "from google.colab import drive \n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls drive/My\\ Drive/GAN_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3mfOf7fNvqhF"
   },
   "source": [
    "## 必要なライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_6J_Mj5JvcXw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "38Ee1vFY1Iyn"
   },
   "source": [
    "# GANの基本構造の構築\n",
    "- 入力画像の型定義\n",
    "- Discriminatorのモデル定義（それぞれの層、活性化関数など）、コンパイル\n",
    "- Generatorのモデル定義（それぞれの層、活性化関数など）、コンパイル（コンビネーションさせること注意）\n",
    "\n",
    "参考\n",
    "- Gneratorの活性化関数LeakyRELUについては[こちら](http://www.thothchildren.com/chapter/59b93f7575704408bd4300f2)　　\n",
    "- 最適化手法の種類については[こちら](https://qiita.com/tkazusa/items/4562cc7080105d5c78a9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "feUPU871nQMS",
    "outputId": "46a3476c-0fdc-4b9b-c707-24269365c629"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 533,505\n",
      "Trainable params: 533,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 784)               803600    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 1,486,352\n",
      "Trainable params: 1,486,352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Gモデルの構築関数\n",
    "def build_generator():\n",
    "    noise_shape = (z_dim,)\n",
    "    model = Sequential()\n",
    "\n",
    "    #入力層（入力の型はランダムノイズz、出力の型は256ノード、活性化関数はReLU）\n",
    "    model.add(Dense(256, input_shape=noise_shape, activation='relu'))\n",
    "\n",
    "    #中間層（入力の型は256ノード、出力の型は512ノード、活性化関数はReLU）\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "\n",
    "    #中間層（入力の型は512ノード、出力の型は1024ノード、活性化関数はReLU）\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "\n",
    "    #中間層（入力の型は1024ノード、出力の型は784（28×28×1）ノード、活性化関数はtanh）\n",
    "    model.add(Dense(np.prod(img_shape), activation='tanh'))\n",
    "\n",
    "    #出力層（28×28×1の画像として出力）\n",
    "    model.add(Reshape(img_shape))\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "#Dモデルの構築関数\n",
    "def build_discriminator():\n",
    "    img_shape = (img_rows, img_cols, channels)\n",
    "    model = Sequential()\n",
    "\n",
    "    #入力層（入力の型は画像、出力の型は512ノード、活性化関数はReLU）\n",
    "    model.add(Flatten(input_shape=img_shape))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "\n",
    "    #中間層（入力の型は512ノード、出力の型は256ノード、活性化関数はReLU）\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "\n",
    "    #出力層（シグモイド関数で0〜1の値として出力）\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "#GモデルとDモデルを合併させる関数（Dモデルの学習は停止）\n",
    "def build_combined1():\n",
    "    discriminator.trainable = False\n",
    "    model = Sequential([generator, discriminator])\n",
    "    return model\n",
    "\n",
    "\n",
    "#入力画像（mnistデータ）の型\n",
    "img_rows = 28 \n",
    "img_cols = 28\n",
    "channels = 1\n",
    "img_shape = (img_rows, img_cols, channels)\n",
    "\n",
    "#潜在変数の次元数 \n",
    "z_dim = 100\n",
    "\n",
    "#最適化手法（Adamを使用（学習率、浮動小数点数を引数））\n",
    "optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "#Dモデル構築(欠損関数、最適化手法、評価関数)\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=optimizer,metrics=['accuracy'])\n",
    "\n",
    "#Gモデル構築(欠損関数、最適化手法、評価関数)\n",
    "generator = build_generator()\n",
    "combined = build_combined1() #Dモデルとのコンビネーションネットワークとして最適化させる\n",
    "combined.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RYYQiZ538M8r"
   },
   "source": [
    "# 学習部分\n",
    "- MNISTの画像データ読み込み\n",
    "- 訓練データの画像と、Gモデルの生成した画像を用意\n",
    "- Dモデル：訓練データは「１」と認識し、生成データは「０」と認識するように、損失関数を元にそれぞれ学習\n",
    "- Gモデル：生成データをDモデルが「１」と認識するように、損失関数を元に学習\n",
    "\n",
    "参考\n",
    "- [欠損値関数とは？](損失関数を元に学習)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9l3PlupsnYCA"
   },
   "outputs": [],
   "source": [
    "def train(epochs, batch_size=128, save_interval=50): \n",
    "    # 教師データ（mnist）の画像を読み込み\n",
    "    (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "    # 画像のそれぞれの値を-1〜1に規格化\n",
    "    X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "    X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "    half_batch = int(batch_size / 2)\n",
    "\n",
    "    # batch_size × epochs回繰り返す\n",
    "    for epoch in range(epochs):\n",
    "        for iteration in range(batch_size):\n",
    "            # バッチサイズの半数をGeneratorから生成\n",
    "            noise = np.random.normal(0, 1, (half_batch, z_dim))\n",
    "            gen_imgs = generator.predict(noise)\n",
    "\n",
    "            # バッチサイズの半数を教師データからピックアップ\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            # ---------------------\n",
    "            #  Discriminatorの学習\n",
    "            # ---------------------\n",
    "            # 訓練データを「1」と認識するよう、欠損値関数を元に学習\n",
    "            d_loss_real = discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "\n",
    "            # 生成データを「0」と認識するよう、欠損値関数を元に学習\n",
    "            d_loss_fake = discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "\n",
    "            # 欠損値の平均を算出\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Generatorの学習\n",
    "            # ---------------------\n",
    "            noise = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "            valid_y = np.array([1] * batch_size)\n",
    "\n",
    "            # 生成データをDモデルが「１」と認識するように、損失関数を元に学習\n",
    "            g_loss = combined.train_on_batch(noise, valid_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成画像の保存\n",
    "- 保存先の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2TGv_G3QnaZj"
   },
   "outputs": [],
   "source": [
    "def save_imgs(epoch):\n",
    "    # 生成画像を敷き詰めるときの行数、列数\n",
    "    r, c = 5, 5\n",
    "\n",
    "    noise = np.random.normal(0, 1, (r * c, z_dim))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    # 生成画像を0-1に再スケール\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "            axs[i,j].axis('off')\n",
    "            cnt += 1\n",
    "#     fig.savefig(\"drive/My Drive/GAN_images/mnist_%d.png\" % epoch)\n",
    "    fig.savefig(\"mnist_%d.png\" % epoch)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z-W8uEZcTqek"
   },
   "source": [
    "# 実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ZICeK90KncvW",
    "outputId": "6b949c01-30bc-44ad-e85d-54394f94d26f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/keras/engine/training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "経過時間：399.6381621360779\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t1 = time.time() \n",
    "train(epochs=100, batch_size=100, save_interval=5)\n",
    "t2 = time.time()\n",
    "\n",
    "# 経過時間を表示\n",
    "elapsed_time = t2-t1\n",
    "print(f\"経過時間：{elapsed_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0kvRNEFWneVf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Original_GAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
